<?php

namespace App\Console;

use Illuminate\Console\Scheduling\Schedule;
use Illuminate\Foundation\Console\Kernel as ConsoleKernel;

class Kernel extends ConsoleKernel
{
    /**
     * The Artisan commands provided by your application.
     *
     * @var array
     */
    protected $commands = [
        Commands\ConsortiumCommand::class,
        Commands\C5Test::class,
        Commands\SushiBatch::class,
        Commands\SushiQLoader::class,
        Commands\SushiQWorker::class,
        Commands\DataArchiveCommand::class,
        Commands\DataPurgeCommand::class,
    ];

    /**
     * Define the application's command schedule.
     *
     * @param  \Illuminate\Console\Scheduling\Schedule  $schedule
     * @return void
     */
    protected function schedule(Schedule $schedule)
    {
    /*----------------------------------------------------------------------------------
     * Example scheduler setup for a 2-consortia system. Each consortium uses a daily
     * queue-loading process (:sushiloader) and 2 queue worker processes that execute
     * every ten minutes (and then exit if there's nothing to do.)
     *
     * Note that the *_QW2 workers have a 5-second startup delay to prevent the _QW1 and
     * _QW2 processes from trying to grab the same job when they start.
     * Syntax:
     *   ccplus:sushiqw  consortium-ID-or-Key [Process-Identifier] [startup-delay]
     *----------------------------------------------------------------------------------
     */
      /*
       * Consortium #1
       */
        // Scan providers for consortium:1, daily, to load any scheduled requests into the ccplus_global.jobs table
        $schedule->command('ccplus:sushiloader 1')->daily();
        // Scan+Process the global jobs table and requests reports; Raw JSON data files are saved to
        // ccplus_global.global_settings:report_path . {consortium_id} . "/0_unprocessed/"
        $schedule->command('ccplus:sushiharvester')->runInBackground()->everyTenMinutes()->withoutOverlapping()
                                                   ->appendOutputTo('/var/log/ccplus/harvests.log');
        // Run one processor per consortium - FIFO
        $schedule->command('ccplus:reportprocessor 1 t ConsoQW1')->runInBackground()->everyTenMinutes()->withoutOverlapping()
                                                                 ->appendOutputTo('/var/log/ccplus/harvests.log');
        // This processor would follow "dorder" assignments in the ccplus_global.reports table
        // (default as installation would be:  PR, DR, TR, IR), and then FIFO within each master report
        // $schedule->command('ccplus:reportprocessor 1 d ConsoQW1')->runInBackground()->everyTenMinutes()->withoutOverlapping()
        //                                                          ->appendOutputTo('/var/log/ccplus/harvests.log');
      /*
       * Consortium #2
       */
        // Scan providers for consortium:2, daily, to load any scheduled requests into the ccplus_global.jobs table
        $schedule->command('ccplus:sushiloader 2')->daily();
        // Scan+Process the global jobs table and requests reports; Raw JSON data files are saved to
        // ccplus_global.global_settings:report_path . {consortium_id} . "/0_unprocessed/"
        $schedule->command('ccplus:sushiharvester')->runInBackground()->everyTenMinutes()->withoutOverlapping()
                                                   ->appendOutputTo('/var/log/ccplus/harvests.log');
        // Run one processor per consortium - FIFO
        $schedule->command('ccplus:reportprocessor 2 t ConsoQW2')->runInBackground()->everyTenMinutes()->withoutOverlapping()
                                                                 ->appendOutputTo('/var/log/ccplus/harvests.log');
    }

    /**
     * Register the commands for the application.
     *
     * @return void
     */
    protected function commands()
    {
        $this->load(__DIR__ . '/Commands');
        require base_path('routes/console.php');
    }
}
